##################################################
##################################################
#' Bootstrap data
#' 
#' The BootstrapData model data is a list of the data specified using \code{OutputProcesses} in \code{\link{Bootstrap}}, where each table is rbinded over all bootstrap runs, added the BootstrapID.
#' 
#' @name BootstrapData
#' 
NULL


#' Bootstrap the baseline model
#' 
#' Run a subset of the baseline model a number of times after resampling e.g. Hauls in each Stratum, EDUSs in each Stratum.
#' 
#' @param outputData The output of the function from an earlier run.
#' @param projectPath The path to the project to containing the baseline to bootstrap.
#' @param BootstrapMethodTable A table of the columns ProcessName, ResampleFunction and Seed, where each row defines the resample function to apply to the output of the given process, and the seed to use in the resampling. The seed is used to draw one seed per bootstrap run using \code\link[RstoxBase]{getSeedVector}}. Run RstoxFramework::getResampleFunctions() to get a list of the implemented resample functions. Note that if a process is selected inn \code{BootstrapMethodTable} that is not used in the model up to the \code{OutputProcesses}, the bootstrapping of that process will not be effective on the end result (e.g. select the correct process that returns BioticAssignment data type).
#' @param NumberOfBootstraps Integer: The number of bootstrap replicates.
#' @param OutputProcesses A vector of the processes to save from each bootstrap replicate.
#' @param UseOutputData Logical: Bootstrapping can be time consuming, and by setting \code{UseOutputData} to TRUE the output file generated by a previous run of the process will be used instead of re-running the bootstrapping. Use this parameter with caution. Any changes made to the Baseline model or to the parameters of the Bootstrap itself will not be accounted for unless UseOutputData = FALSE. The option UseOutputData = TRUE is intended only for saving time when one needs to generate a report from an existing Bootstrap run."
#' @param NumberOfCores The number of cores to use for parallel processing. A copy of the project is created in tempdir() for each core, also when using only one core. Note that this will require disc space equivalent to the \code{NumberOfCores} time the size of the project folder (excluding the output/analysis/Bootstrap folder, which will be deleted before copies are made).
#' @param BaselineSeedTable A table of ProcessName and Seed, givng the seed to use for the Baseline processes that requires a Seed parameter. The seed is used to draw one seed per bootstrap run using \code\link[RstoxBase]{getSeedVector}}.
#' 
#' @details A copy of the project is made for each core given by \code{NumberOfCores}. In the case that NumberOfCores == 1, this is still done for safety.
#' 
#' @return
#' A \code{\link{BootstrapData}} object, which is a list of the RstoxData \code{\link[RstoxData]{DataTypes}} and RstoxBase \code{\link[RstoxBase]{DataTypes}}.
#' 
#' @export
#' 
Bootstrap <- function(
    outputData, 
    projectPath, 
    # Table with ProcessName, ResamplingFunction, ResampleWithin, Seed:
    BootstrapMethodTable = data.table::data.table(), 
    NumberOfBootstraps = 1L, 
    OutputProcesses = character(), 
    UseOutputData = FALSE, 
    NumberOfCores = 1L, 
    BaselineSeedTable = data.table::data.table()
) {
    
    # Use preivously generated output data if specified:
    if(UseOutputData) {
        warning("StoX: Using UseOutputData = TRUE in the function Bootstrap implies reading the BootstrapData from a previous run (stored in the output folder)). Any changes made to the Baseline model or to the parameters of the Bootstrap itself will not be accounted for unless UseOutputData = FALSE. The option UseOutputData = TRUE is intended only for saving time when one needs to generate a report from an existing Bootstrap run.")
        # This was moved to getFunctionArguments() on 2020-10-22:
        #outputData <- get(load(outputDataPath))
        
        # Read the outputData (from a former run of the proecss). Use functionArguments["outputData"] to add the data, since using functionArguments$outputData will delete this element if trying to giev it the value NULL:
        if(is.character(outputData)) {
            if(length(outputData)) {
                if(!file.exists(outputData)) {
                    stop("The file ", outputData, " does not exist. Please re-run the Bootstrap process.")
                }
                else {
                    outputData <- tryCatch(
                        get(load(outputData)), 
                        error = function(err) list(NULL)
                    )
                }
            }
            else {
                outputData <- list(NULL)
            }
        }
        
        return(outputData)
    }
    # Identify the first process set for resampling by the BootstrapMethodTable (here BootstrapMethodTable$ProcessName can be a vector, in which case the table is returned from the first process of these and onwards):
    processesSansProcessData <- getProcessesSansProcessData(projectPath, modelName = "baseline", startProcess = BootstrapMethodTable$ProcessName, endProcess = OutputProcesses, return.processIndex = TRUE)
    
    # Check the output processes:
    if(length(OutputProcesses) && !all(OutputProcesses %in% processesSansProcessData$processName)) {
        stop("StoX: The following processes specified in OutputProcesses were not recognized: ", paste(setdiff(OutputProcesses, processesSansProcessData$processName), collapse = ", "))
        OutputProcesses <- intersect(OutputProcesses, processesSansProcessData$processName)
    }
    if(!length(OutputProcesses)) {
        stop("StoX: At least one valid process name must be given in OutputProcesses")
    }
    
    # The baseline must have been run until the last output process:
    activeProcessIndex <- getProcessIndexFromProcessID(
        projectPath = projectPath, 
        modelName = "baseline", 
        processID = getActiveProcess(
            projectPath = projectPath, 
            modelName = "baseline"
        )$processID
    )
    #preRunTo <- min(processesSansProcessData$processIndex) - 1
    # preRunTo <- min(processesSansProcessData$processIndex)
    #if(activeProcessID < preRunTo) {
    
    baselineMustHaveBeenRunTo <- max(processesSansProcessData$processIndex)
    if(activeProcessIndex < baselineMustHaveBeenRunTo) {
        #message("StoX: Running baseline until the first process to bootstrap...")
        #temp <- runProcesses(
        #    projectPath, 
        #    modelName = "baseline", 
        #    endProcess = preRunTo, 
        #    save = FALSE, 
        #    saveProcessData = FALSE
        #)
        stop("The Baseline model must be run at least until the last output process \"", getProcessNameFromProcessID(projectPath, modelName = "baseline", processID = processesSansProcessData[processIndex == baselineMustHaveBeenRunTo, processID]), "\"")
    }
    
    # Draw the seeds in a table, and then split into a list for each bootstrap run:
    #SeedTable <- data.table::as.data.table(lapply(BootstrapMethodTable$Seed, RstoxBase::getSeedVector, size = NumberOfBootstraps))
    #names(SeedTable) <- BootstrapMethodTable$ProcessName
    #SeedList <- split(SeedTable, seq_len(nrow(SeedTable)))
    NumberOfBootstraps <- NumberOfBootstraps
    SeedList <- drawSeedList(
        table = BootstrapMethodTable, 
        NumberOfBootstraps = NumberOfBootstraps, 
        listOf = "table"
    )
    # Create the replaceDataList input to runProcesses, which defines the seed for each bootstrap run:
    replaceDataList <- createReplaceData(SeedList = SeedList, BootstrapMethodTable = BootstrapMethodTable)
    
    # Scan through the baseline processes to be run and look for processes with the parameter Seed:
    hasSeed <- sapply(processesSansProcessData$functionParameters, function(x) "Seed" %in% names(x))
    # Error if the BaselineSeedTable does not contain exactly the processes using Seed in the Baseline processes to be run:
    if(any(hasSeed)) {
        presentInBaselineButNotInBaselineSeedTable <- setdiff(
            processesSansProcessData$processName[hasSeed], 
            BaselineSeedTable$ProcessName
        )
        presentInBaselineSeedTableButNotInBaseline <- setdiff(
            BaselineSeedTable$ProcessName, 
            processesSansProcessData$processName[hasSeed]
        )
        if(length(presentInBaselineButNotInBaselineSeedTable) || length(presentInBaselineSeedTableButNotInBaseline)) {
            stop("The BaselineSeedTable must contain Seed for the processes (and only the processes) ", paste(processesSansProcessData$processName[hasSeed], collapse = ", "), ".")
        }
    }
    # Construct a list of lists, where each list contains a list of Seed named by the processes using Seed in the Baseline:
    BaselineSeedList <- drawSeedList(
        table = BaselineSeedTable, 
        NumberOfBootstraps = NumberOfBootstraps, 
        listOf = "list"
    )
    replaceArgsList <- BaselineSeedList
    #replaceArgsList <- lapply(replaceArgsList, function(x) lapply(x, function(y) list(Seed = y)))
    
    # Get the number of cores to open:
    NumberOfCores <- RstoxData::getNumberOfCores(NumberOfCores, n  = NumberOfBootstraps)
    
    # Copy the project to the tempdir for each core:
    projecName <- basename(projectPath)
    # As of 2021-05-27 (v3.0.23) make a copy even if running on only one core. This for safety:
    #if(NumberOfCores > 1)  {
    projectPath_copies <- file.path(tempdir(), paste0(projecName, seq_len(NumberOfCores)))
    temp <- RstoxData::mapplyOnCores(
        copyProject, 
        projectPath = projectPath, 
        newProjectPath = projectPath_copies, 
        MoreArgs = list(
            ow = TRUE, 
            empty.output = TRUE
        ), 
        NumberOfCores = NumberOfCores
    )
    #}
    #else {
    #    projectPath_copies <- projectPath
    #}
    
    # Run the subset of the baseline model:
    #bootstrapProgressFile <- getProjectPaths(projectPath, "bootstrapProgressFile")
    bootstrapProgressFile <- getProjectPaths(projectPath, "progressFile")$analysis
    NumberOfBootstrapsFile <- getProjectPaths(projectPath, "NFile")$analysis
    stopBootstrapFile <- getProjectPaths(projectPath, "stopFile")$analysis
    if(file.exists(stopBootstrapFile)) {
        unlink(stopBootstrapFile, force = TRUE, recursive = TRUE)
    }
    
    # Delete files on exit:
    on.exit(unlink(NumberOfBootstrapsFile, force = TRUE, recursive = TRUE))
    on.exit(unlink(bootstrapProgressFile, force = TRUE, recursive = TRUE), add = TRUE)
    on.exit(unlink(projectPath_copies, force = TRUE, recursive = TRUE), add = TRUE)
    on.exit(if(file.exists(stopBootstrapFile)) unlink(stopBootstrapFile, force = TRUE, recursive = TRUE), add = TRUE)
    
    
    # Prepare for progress info:
    writeLines(as.character(NumberOfBootstraps), NumberOfBootstrapsFile)
    
    # Run the bootstrap:
    bootstrapIndex <- seq_len(NumberOfBootstraps)
    BootstrapData <- RstoxData::mapplyOnCores(
        FUN = runOneBootstrapSaveOutput, 
        NumberOfCores = NumberOfCores, 
        # Vector inputs:
        ind = bootstrapIndex, 
        replaceArgsList = replaceArgsList, 
        replaceDataList = replaceDataList, 
        projectPath = projectPath_copies, 
        
        # Other inputs:
        MoreArgs = list(
            projectPath_original = projectPath, 
            startProcess = min(processesSansProcessData$processIndex), 
            endProcess = max(processesSansProcessData$processIndex), 
            outputProcessesIDs = OutputProcesses, 
            bootstrapProgressFile = bootstrapProgressFile, 
            stopBootstrapFile = stopBootstrapFile
        )
    )
    
    # Here we need to merge the NeCDF4 bootstrap files, when we get these files implemented. For now all bootstrap data are accumulated in memory and dumped to an RData file.
    
    # Changed on 2020-11-02 to run the baseline out after bootstrapping (with no modification, so a clean baseline run):
    ### # Reset the model to the last process before the bootstrapped processes:
    ### resetModel(
    ###     projectPath = projectPath, 
    ###     modelName = "baseline", 
    ###     processID = processesSansProcessData$processID[1], 
    ###     processDirty = FALSE, 
    ###     shift = -1
    ### )
    
    
    ## Rerun the baseline processes that were run in the bootstrapping:
    #temp <- runProcesses(
    #    projectPath, 
    #    modelName = "baseline", 
    #    startProcess = min(processesSansProcessData$processIndex), 
    #    endProcess = max(processesSansProcessData$processIndex, activeProcessIndex), 
    #    save = FALSE, 
    #    # Be sure to not touch the process data and file output:
    #    saveProcessData = FALSE, 
    #    fileOutput = FALSE
    #)
    
    
    
    
    
    
    processNames <- names(BootstrapData[[1]])
    processIDs <- unlist(
        mapply(
            getProcessIDFromProcessName, 
            processName = processNames, 
            MoreArgs = list(
                projectPath = projectPath, 
                modelName = "baseline"
            ), 
            only.processID = TRUE, 
            SIMPLIFY = FALSE
        )
    )
    dataTypes <- unlist(
        mapply(
            getDataType, 
            processID = processIDs, 
            MoreArgs = list(
                projectPath = projectPath, 
                modelName = "baseline"
            ), 
            SIMPLIFY = FALSE
        )
    )
    
    
    
    # Add the process names after rbinding each output:
    bootstrapDataNames <- names(BootstrapData[[1]])
    BootstrapData <- lapply(bootstrapDataNames, rbindlistByName, x = BootstrapData)
    names(BootstrapData) <- bootstrapDataNames
    
    # Drop the list for data types with only one table:
    for(bootstrapDataName in names(BootstrapData)) {
        if(isProcessOutputDataType(BootstrapData[[bootstrapDataName]])) {
            BootstrapData[[bootstrapDataName]] <- BootstrapData[[bootstrapDataName]][[1]]
        }
    }
    
    # Set the dataTypes as attributes:
    for(bootstrapDataName in names(BootstrapData)) {
        attr(BootstrapData[[bootstrapDataName]], "dataType") <- dataTypes[[bootstrapDataName]]
    }
    
    
    
    
    return(BootstrapData)
}


# Funcion to draw seeds for each process given in the table and each bootstrap run, and reshape the seeds into a list of either data.table with rows 
drawSeedList <- function(table, NumberOfBootstraps, listOf = c("table", "list")) {
    if(!length(table)) {
        SeedList <- vector("list", NumberOfBootstraps)
        if(listOf == "list") {
            SeedList <- lapply(SeedList, as.data.table)
        }
    }
    else {
        SeedTable <- data.table::as.data.table(lapply(table$Seed, RstoxBase::getSeedVector, size = NumberOfBootstraps))
        names(SeedTable) <- table$ProcessName
        SeedList <- split(SeedTable, seq_len(nrow(SeedTable)))
        if(listOf == "list") {
            SeedList <- lapply(SeedList, function(x) structure(as.list(x), names = names(x)))
        }
    }
    
    return(SeedList)
}


rbindlistByName <- function(name, x) {
    subnames <- names(x[[1]][[name]])
    out <- lapply(subnames, rbindSublistByName, name, x)
    names(out) <- subnames
    return(out)
}
rbindSublistByName <- function(subname, name, x) {
    data.table::rbindlist(lapply(x, function(y) y[[name]][[subname]]))
}


# Function to create a list of the ReplaceData input to runProcesses(), 
createReplaceDataSansFunctionName <- function(Seed) {
    lapply(Seed, function(x) list(MoreArgs = list(Seed = x)))
}
addFunctionNameToReplaceData <- function(replaceData, BootstrapMethodTable) {
    out <- lapply(names(replaceData), function(name) 
        c(
            list(FunctionName = BootstrapMethodTable[ProcessName == name, ResampleFunction]), 
            replaceData[[name]]
        ))
    # Add the process names to the list to enable replaceDataList in runProcesses():
    names(out) <- names(replaceData)
    return(out)
}
createReplaceData <- function(SeedList, BootstrapMethodTable) {
    replaceDataList <- lapply(SeedList, createReplaceDataSansFunctionName)
    replaceDataList <- lapply(replaceDataList, addFunctionNameToReplaceData, BootstrapMethodTable = BootstrapMethodTable)
    return(replaceDataList)
}


# Define a function to run processes and save the output of the last process to the output folder:
runOneBootstrapSaveOutput <- function(ind, replaceArgsList, replaceDataList, projectPath, projectPath_original, startProcess, endProcess, outputProcessesIDs, bootstrapProgressFile, stopBootstrapFile) {
    
    # Stop if the file stopBootstrap.txt exists:
    if(file.exists(stopBootstrapFile)) {
        stop("Bootstrap aborted by the user.")
    }
    
    # Run the part of the baseline that containes the processes to be modified to those to be returned:
    runProcesses(
        projectPath, 
        modelName = "baseline", 
        startProcess = startProcess, 
        endProcess = endProcess, 
        save = FALSE, 
        # Be sure to not touch the process data and file output, the latter mostly for speed if the bootstrap is run on a copy of the project (see if this is the case in the code of Bootstrap()):
        saveProcessData = FALSE, 
        #  Do not save the output (text) files:
        fileOutput = FALSE, 
        setUseProcessDataToTRUE = FALSE, 
        replaceArgsList = replaceArgsList, 
        replaceDataList = replaceDataList, 
        msg = FALSE
    )
    
    # Get the requested outputs:
    processOutput <- getModelData(
        projectPath = projectPath, 
        modelName = "baseline", 
        processes = outputProcessesIDs, 
        drop.datatype = FALSE
    )
    
    # Add bootstrap IDs to the processOutput:
    for(dataType in names(processOutput)) {
        for(table in names(processOutput[[dataType]])) {
            # This did not work for some reason (https://stackoverflow.com/questions/51877642/adding-a-column-by-reference-to-every-data-table-in-a-list-does-not-stick):
            # processOutput[[dataType]][[table]][, BootstrapID := ..ind]
            # So we do it not by reference:
            processOutput[[dataType]][[table]]$BootstrapID <- ind
        }
    }
    
    # Add a dot to the progess file:
    cat(".", file = bootstrapProgressFile, append = TRUE)
    
    return(processOutput)
}


### #' Stop a bootstrap run.
### #' 
### #' @inheritParams general_arguments
### #' 
### #' @export
### #' 
### stopBootstrap <- function(projectPath) {
###     write("", file = getProjectPaths(projectPath, "stopBootstrapFile"))
### }
#' Stop runProcesses().
#' 
#' @inheritParams general_arguments
#' 
#' @export
#' 
stopProcesses <- function(projectPath, modelName) {
    stopFile <- getProjectPaths(projectPath, "stopFile")[[modelName]]
    write("", file = stopFile)
}
#' Get process progress
#' 
#' @inheritParams general_arguments
#' @param percent Logical: If TRUE return the progress in percent, otherwise in [0,1].
#' 
#' @export
#' 
progressOfProcesses <- function(projectPath, modelName, percent = FALSE) {
    # Get the paths to the progress and N files:
    ProgressFile <- getProjectPaths(projectPath, "progressFile")[[modelName]]
    NFile <- getProjectPaths(projectPath, "NFile")[[modelName]]
    if(!file.exists(ProgressFile)) {
        return(NA)
    }
    # Read number of dots and compare the N:
    N <- as.numeric(readLines(NFile, warn = FALSE))
    Progress <- readLines(ProgressFile, warn = FALSE)
    n <- lengths(regmatches(Progress, gregexpr(".", Progress)))
    Progress <- n / N
    if(percent) {
        Progress <- Progress * 100
    }
    return(Progress)
}
#' Get process progress
#' 
#' @inheritParams general_arguments
#' @param string.out Logical: If TRUE return a string listing the time remaining and the total estimated time.
#' 
#' @export
#' 
estimateTimeOfProcesses <- function(projectPath, modelName, string.out = TRUE) {
    # Get progress:
    progress <- progressOfProcesses(projectPath, modelName)
    # Read time of NFile:
    NFile <- getProjectPaths(projectPath, "NFile")$analysis
    if(!file.exists(NFile)) {
        return(NA)
    }
    startTime <- file.info(NFile)$ctime
    # And compare to the present time:
    now <- Sys.time()
    timeUsed <- now - startTime
    
    # Predict the total time:
    totalTimePredicted <- timeUsed / progress
    
    # Predict time remaninig:
    remainingTimePredicted <- totalTimePredicted - timeUsed
    
    # Paste to a string message:
    if(string.out) {
        output <- paste0("Estimated ", round(remainingTimePredicted, 1), " ", attr(remainingTimePredicted, "units"), " remaining (", 100 * progress, " percent elapsed of total estimated time ", round(totalTimePredicted, 1), " ", attr(totalTimePredicted, "units"), ")")
    }
    else {
        output <- remainingTimePredicted
    }
    
    
    return(output)
}



addBootstrapID <- function(x, ind) {
    if(is.list(x) && !data.table::is.data.table(x)){
        lapply(x, addBootstrapIDOne, ind = ind)
    }
    else {
        addBootstrapIDOne(x, ind = ind)
    }
}

addBootstrapIDOne <- function(x, ind) {
    x[, BootstrapID := ..ind]
}




#readBootstrap <- function(projectPath, processName) {
#    # Bootstrap lives in the model "analysis" only:
#    modelName = "analysis"
#    # Get the folder holding the output form the bootstrap:
#    processID <- getProcessIDFromProcessName(projectPath = projectPath, modelName = modelName, processName = processName)
#    folderPath <- getProcessOutputFolder(projectPath = projectPath, modelName = modelName, processID = processID, type = "output")
#    
#    # Return NULL if the folder does not exist:
#    if(!file.exists(folderPath)) {
#        warning("StoX: The process ", folderPath, " does not have an output folder. Has the proccess been run?")
#        return(NULL)
#    }
#    
#    # Get a nested list of all output files from the bootstrap:
#    bootstrapOutputFiles <- getFilesRecursiveWithOrder(folderPath)
#    
#    # Read all files:
#    processOutput <- rapply(
#        bootstrapOutputFiles, 
#        readProcessOutputFile, 
#        how = "replace"
#    )
#    
#}


# # Function to get the name of the bootsrap run, which will be used as the subfolder name hoding the output from the bootstrap:
# getBootstrapRunName <- function(ind, NumberOfBootstraps, prefix = "Run") {
#     paste0(
#         prefix, 
#         formatC(ind, width = NumberOfBootstraps, format = "d", flag = "0")
#     )
# }


#getReplaceData <- function(x, size) {
#    # Get seeds:
#    seeds <- RstoxBase::getSeedVector(x$Seed, size)
#    x_expanded <- data.table::data.table(
#        x[, !"Seed"], 
#        Seed = seeds
#    )
#    
#    # Split rows into a list:
#    x_split <- split(x_expanded, by = "Seed")
#    
#    x_split <- lapply(x_split, function(x) list(x$ResampleFunction, as.list(x[, !c("ResampleFunction")])))
#    
#    return(x_split)
#}




# This function resamples varToResample with replacement by altering the input data. Used in ResampleMeanLengthDistributionData(), ResampleBioticAssignment() and ResampleMeanNASCData():
resampleDataBy <- function(data, seed, varToScale, varToResample, resampleBy) {
    
    # Get the unique resampleBy, and sort in C-locale for consistensy across platforms:
    #uniqueResampleBy <- unique(data[[resampleBy]])
    #uniqueResampleBy <- stringi::stri_sort(unique(data[[resampleBy]]), locale = "C")
    
    # Get the unique resampleBy, and sort in en_US_POSIX for consistensy across platforms:
    uniqueResampleBy <- stringi::stri_sort(unique(data[[resampleBy]]), locale = "en_US_POSIX")
    
    # Build a table of (usually) Stratum and Seed and merge with the MeanLengthDistributionData:
    seedTable <- data.table::data.table(
        resampleBy = uniqueResampleBy, 
        seed = RstoxBase::getSeedVector(seed, size = length(uniqueResampleBy))
    )
    data.table::setnames(seedTable, c(resampleBy, "seed"))
    data <- merge(data, seedTable, by = resampleBy)
    
    # Resample the data:
    for(var in varToScale) {
        data[, eval(var) := resampleOne(.SD, seed = seed[1], varToScale = var, varToResample = varToResample), by = resampleBy]
    }
    
    data[, seed := NULL]
    #return(MeanLengthDistributionData)
}

# Function to resample Hauls of one subset of the data:
resampleOne <- function(subData, seed, varToResample, varToScale) {
    
    # Resample the unique:
    if(length(varToResample) != 1) {
        stop("StoX: varToResample must be a single string naming the variable to resample")
    }
    resampled <- RstoxBase::sampleSorted(unique(subData[[varToResample]]), seed = seed, replace = TRUE)
    # Tabulate the resamples:
    #resampleTable <- table(resampled)
    #if(!length(resampleTable)) {
    #    
    #}
    resampleTable <- data.table::as.data.table(table(resampled, useNA = "ifany"))
    # Set an unmistakable name to the counts:
    data.table::setnames(resampleTable, c("resampled","N"), c(varToResample, "resampledCountWithUniqueName"))
    
    # Merge the resampled counts into the data:
    # The sort = FALSE is very important, as it retains the order of the data. This should probably be replaced by a more robust solution, e.g. by merging in resampleDataBy():
    count <- merge(subData, resampleTable, by = varToResample, all.x = TRUE, sort = FALSE)
    
    # Insert the new count into varToScale (with NAs replaced by 0):
    count[, resampledCountWithUniqueName := ifelse(
        is.na(count$resampledCountWithUniqueName), 
        0, 
        count$resampledCountWithUniqueName
    )]
    
    #count[, eval(varToScale) := lapply(get(varToScale), "*", resampledCountWithUniqueName)]
    count[, eval(varToScale) := resampledCountWithUniqueName * get(varToScale)]
    
    return(count[[varToScale]])
}


#' Resamples biotic PSUs within Stratum in MeanLengthDistributionData
#' 
#' This function resamples biotic PSUs with replacement within each Stratum, changing the MeanLengthDistributionWeight.
#' 
#' @inheritParams RstoxBase::ModelData
#' @param Seed The seed, given as a sinigle initeger.
#' 
#' @export
#' 
ResampleMeanLengthDistributionData <- function(MeanLengthDistributionData, Seed) {
    
    # This function will be renamed to ResampleBioticPSUsInStratum
    
    # Resample PSUs within Strata, modifying the weighting variable of MeanLengthDistributionData:
    MeanLengthDistributionData$Data <- resampleDataBy(
        data = MeanLengthDistributionData$Data, 
        seed = Seed, 
        #varToScale = RstoxBase::getRstoxBaseDefinitions("dataTypeDefinition")[["MeanLengthDistributionData"]]$weighting, 
        varToScale = "WeightedNumber", 
        # If any other values than varToResample = "PSU" and resampleBy = "Stratum" are used in the future, warnings for only one and not all varToResample in resampleBy should be added in RstoxBase!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!:
        varToResample = "PSU", 
        resampleBy = "Stratum"
    )
    
    return(MeanLengthDistributionData)
}



#' Resamples biotic PSUs within Stratum in MeanSpeciesCategoryCatchData
#' 
#' This function resamples biotic PSUs with replacement within each Stratum, changing the MeanSpeciesCategoryCatchData
#' 
#' @inheritParams RstoxBase::ModelData
#' @param Seed The seed, given as a sinigle initeger.
#' 
#' @export
#' 
ResampleMeanSpeciesCategoryCatchData <- function(MeanSpeciesCategoryCatchData, Seed) {
    
    # This function will be renamed to ResampleBioticPSUsInStratum
    
    # Resample PSUs within Strata, modifying the weighting variable of MeanSpeciesCategoryCatchData:
    MeanSpeciesCategoryCatchData$Data <- resampleDataBy(
        data = MeanSpeciesCategoryCatchData$Data, 
        seed = Seed, 
        varToScale = c("TotalCatchWeight", "TotalCatchNumber"), 
        # If any other values than varToResample = "PSU" and resampleBy = "Stratum" are used in the future, warnings for only one and not all varToResample in resampleBy should be added in RstoxBase!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!:
        varToResample = "PSU", 
        resampleBy = "Stratum"
    )
    
    return(MeanSpeciesCategoryCatchData)
}


### #' Resamples biotic PSUs
### #' 
### #' This function resamples biotic PSUs with replacement within each Stratum, changing the MeanLengthDistributionWeight.
### #' 
### #' @param MeanLengthDistributionData The \code{\link[RstoxBase]{MeanLengthDistributionData}} data.
### #' @param Seed The seed, given as a sinigle initeger.
### #' 
### #' @export
### #' 
### ResampleAssignmentLengthDistributionData <- function(AssignmentLengthDistributionData, Seed) {
###     # Resample PSUs within Strata, modifying the weighting variable of AssignmentLengthDistributionData:
###     AssignmentLengthDistributionData <- resampleDataBy(
###         data = AssignmentLengthDistributionData, 
###         seed = Seed, 
###         #varToScale = RstoxBase::getRstoxBaseDefinitions("dataTypeDefinition")[["AssignmentLengthDistributionData"]]$weighting, 
###         varToScale = "WeightedNumber", 
###         varToResample = "PSU", 
###         resampleBy = "Stratum"
###     )
###     
###     return(AssignmentLengthDistributionData)
### }


#' Resamples biotic PSUs
#' 
#' This function resamples biotic PSUs with replacement within each Stratum, changing the MeanLengthDistributionWeight.
#' 
#' @inheritParams RstoxBase::ProcessData
#' @param Seed The seed, given as a sinigle initeger.
#' 
#' @export
#' 
ResampleBioticAssignment <- function(BioticAssignment, Seed) {
    
    # This function will be renamed to ResampleAssignedHaulsInStratum
    
    # Resample Hauls within Strata, modifying the weighting variable of BioticAssignment:
    BioticAssignment <- resampleDataBy(
        #data = BioticAssignment$BioticAssignment, 
        data = BioticAssignment, 
        seed = Seed, 
        varToScale = "WeightingFactor", 
        # If any other values than varToResample = "Haul" and resampleBy = "Stratum" are used in the future, warnings for only one and not all varToResample in resampleBy should be added in RstoxBase!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!:
        varToResample = "Haul", 
        resampleBy = "Stratum"
    )
    
    return(BioticAssignment)
}


#' Resamples acoustic PSUs
#' 
#' This function resamples acoustic PSUs with replacement within each Stratum, changing the MeanNASC
#' 
#' @inheritParams RstoxBase::ModelData
#' @param Seed The seed, given as a sinigle initeger.
#' 
#' @export
#' 
ResampleMeanNASCData <- function(MeanNASCData, Seed) {
    
    # This function will be renamed to ResampleAcousticPSUsInStratum
    
    # Resample PSUs within Strata, modifying the weighting variable of MeanLengthDistributionData:
    MeanNASCData$Data <- resampleDataBy(
        data = MeanNASCData$Data, 
        seed = Seed, 
        #varToScale = RstoxBase::getRstoxBaseDefinitions("dataTypeDefinition")[["MeanNASC"]]$weighting, 
        varToScale = "NASC", 
        varToResample = "PSU", 
        resampleBy = "Stratum"
    )
    
    return(MeanNASCData)
}



#ResampleIndividualAge <- function(SuperIndividualsData, AgeErrorMatrix, Seed) {
#
#    
#
#    return(SuperIndividualsData)
#}



##################################################
##################################################
#' Report Bootstrap
#' 
#' Reports the sum, mean or other statistics on a variable of the \code{\link{BootstrapData}}.
#' 
#' @param BootstrapData The \code{\link{BootstrapData}} data output from \code{\link{Bootstrap}}.
#' @inheritParams RstoxBase::general_report_arguments
#' @param BaselineProcess A strings naming the baseline process to report from the boostrap output.
#' @param AggregationFunction The function to apply to each bootstrap run. This must be a function returning a single value.
#' @param BootstrapReportFunction The function to apply across bootstrap run, such as "cv" or "stoxSummary".
#' @param AggregationWeightingVariable The variable to weight by in the \code{AggregationFunction}.
#' @param BootstrapReportWeightingVariable The variable to weight by in the \code{BootstrapReportFunction}.
#'
#' @details This function works in two steps. First, the \code{AggregationFunction} is applied to the \code{TargetVariable} of the table given by \code{BaselineProcess} for each unique combination of the \code{GroupingVariables} and for each bootstrap run. Second, a grid of all possible combinations of the \code{GroupingVariables} is formed and the result from the first step placed onto the grid. This creates 0 for each position in the grid where data from the first step are not present. E.g., if a particularly large fish is found in only one haul, and this haul by random is not selected in a bootstrap run, the \code{TargetVariable} will be 0 to reflect the variability in the data. To complete the second step, the \code{BootstrapReportFunction} is applied over the bootstrap runs for each cell in the grid.
#' 
#' The parameter \code{RemoveMissingValues} should be used with extreme caution. The effect of setting \code{RemoveMissingValues} to TRUE is that missing values (NAs) are removed in both the first and second step. This can be dangerous both in the first and in the second step. E.g., if the Abundance of \code{\link{SuperIndividualsData}} is positive for super-individuals with missing IndividualWeight, then the Biomass of those super-individuals will be missing as well. If one the wants to sum the Biomass by using \code{AggregationFunction} = "sum" one will get NA if \code{RemoveMissingValues} = FALSE. If \code{RemoveMissingValues} = TRUE one will ignore the missing Biomass, and the summed Biomass will only include the super-individuals that have non-missing IndividualWeight, effectively discarding a portion of the observed abundance. The summed Biomass will in this case be underestimated!
#' 
#' In the second step, setting \code{RemoveMissingValues} to TRUE can be even more dangerous, as the only option currently available for the \code{BootstrapReportFunction} is the function RstoxBase::summaryStox(), which includes average and standard deivation which are highly influenced by removing missing data.
#' 
#' Instead of setting \code{RemoveMissingValues} to TRUE, it is advised to apply the function \code{\link{ImputeSuperIndividuals}} to fill in e.g. IndividualWeight where missing. Missing values in the output from \code{\link{ReportBootstrap}} can also be avoided by adding variables to \code{GroupingVariables}, such as adding "Stratum" e.g. if there are strata that are known from Baseline to contain no fish. These strata will then be present but with missing values, but these missing values will not affect other strata if "Stratum" is included in \code{GroupingVariables}. It is also  recommended to include "Survey" and "SpeciesCategory" in the \code{GroupingVariables}, as these are key variables for which summary statistics should rarely be computed across.
#' 
#' @return
#' A \code{\link{ReportBootstrapData}} object.
#' 
#' @export
#' 
ReportBootstrap <- function(
    BootstrapData, 
    BaselineProcess = character(), 
    TargetVariable = character(), 
    TargetVariableUnit = character(), 
    AggregationFunction = RstoxBase::getReportFunctions(getMultiple = FALSE), 
    BootstrapReportFunction = RstoxBase::getReportFunctions(getMultiple = TRUE), 
    GroupingVariables = character(), 
    InformationVariables = character(), 
    RemoveMissingValues = FALSE, 
    AggregationWeightingVariable = character(), 
    BootstrapReportWeightingVariable = character()
) 
{
    # Store any dataType attribute:
    dataType <- attr(BootstrapData[[BaselineProcess]], "dataType")
    
    # Issue a warning if RemoveMissingValues = TRUE:
    if(isTRUE(RemoveMissingValues)) {
        warning(RstoxBase::getRstoxBaseDefinitions("RemoveMissingValuesWarning")(TargetVariable))
    }
    
    if(! BaselineProcess %in% names(BootstrapData)) {
        # If the BootstrapData is empty, stop:
        if(!length(BootstrapData)) {
            warning("Empty BootstrapData.")
        }
        else {
            stop("The BaselineProcess ", BaselineProcess, " is not one of the outputs of the Bootstrap. Possible values are ", paste(names(BootstrapData), collapse = ", "), ".")
        }
    }
    else if(
        is.list(BootstrapData[[BaselineProcess]]) && 
        all(c("Data", "Resolution")  %in% names(BootstrapData[[BaselineProcess]]))
    ) {
        BootstrapData[[BaselineProcess]] <- BootstrapData[[BaselineProcess]]$Data
    }
    
    ### # Run the initial aggregation (only applicable for single output functions):
    ### AggregationFunction <- RstoxData::match_arg_informative(AggregationFunction)
    ### out <- RstoxBase::aggregateBaselineDataOneTable(
    ###     stoxData = BootstrapData[[BaselineProcess]], 
    ###     TargetVariable = TargetVariable, 
    ###     aggregationFunction = AggregationFunction, 
    ###     GroupingVariables = c(GroupingVariables, "BootstrapID"), 
    ###     InformationVariables = InformationVariables, 
    ###     na.rm = RemoveMissingValues, 
    ###     WeightingVariable = AggregationWeightingVariable
    ### )
    ### 
    ### 
    ### # Get the name of the new TargetVariable:
    ### TargetVariableAfterInitialAggregation <- RstoxBase::getReportFunctionVariableName(
    ###     functionName = AggregationFunction, 
    ###     TargetVariable = TargetVariable
    ### )
    ### 
    ### # Run the report function of the bootstraps:
    ### BootstrapReportFunction <- RstoxData::match_arg_informative(BootstrapReportFunction)
    ### out <- RstoxBase::aggregateBaselineDataOneTable(
    ###     stoxData = out, 
    ###     TargetVariable = TargetVariableAfterInitialAggregation, 
    ###     aggregationFunction = BootstrapReportFunction, 
    ###     GroupingVariables = GroupingVariables, 
    ###     InformationVariables = InformationVariables, 
    ###     na.rm = RemoveMissingValues, 
    ###     padWithZerosOn = "BootstrapID", 
    ###     WeightingVariable = BootstrapReportWeightingVariable
    ### )
    ### 
    ### return(out)
    
    
    # Store the unique combinations of the GroupingVariables from the BootstrapData[[BaselineProcess]]:
    uniqueGroupingVariablesToKeep <- unique(subset(BootstrapData[[BaselineProcess]], select = GroupingVariables))
    setorder(uniqueGroupingVariablesToKeep)
    
     
    
    
    
    BootstrapData[[BaselineProcess]][[TargetVariable]] <- setUnitRstoxBase(
        BootstrapData[[BaselineProcess]][[TargetVariable]], 
        dataType =  dataType, 
        variableName = TargetVariable, 
        unit = TargetVariableUnit
    )
    
    # Run the initial aggregation (only applicable for single output functions):
    AggregationFunction <- RstoxData::match_arg_informative(AggregationFunction)
    output <- RstoxBase::aggregateBaselineDataOneTable(
        stoxData = BootstrapData[[BaselineProcess]], 
        TargetVariable = TargetVariable, 
        aggregationFunction = AggregationFunction, 
        GroupingVariables = c(GroupingVariables, "BootstrapID"), 
        InformationVariables = InformationVariables, 
        na.rm = RemoveMissingValues, 
        WeightingVariable = AggregationWeightingVariable
    )
    
    
    # Get the name of the new TargetVariable:
    TargetVariableAfterInitialAggregation <- RstoxBase::getReportFunctionVariableName(
        functionName = AggregationFunction, 
        TargetVariable = TargetVariable
    )
    
    # Run the report function of the bootstraps:
    BootstrapReportFunction <- RstoxData::match_arg_informative(BootstrapReportFunction)
    output <- RstoxBase::aggregateBaselineDataOneTable(
        stoxData = output, 
        TargetVariable = TargetVariableAfterInitialAggregation, 
        aggregationFunction = BootstrapReportFunction, 
        GroupingVariables = GroupingVariables, 
        InformationVariables = InformationVariables, 
        na.rm = RemoveMissingValues, 
        padWithZerosOn = "BootstrapID", 
        WeightingVariable = BootstrapReportWeightingVariable, 
        uniqueGroupingVariablesToKeep = uniqueGroupingVariablesToKeep
    )
    
    ### # Discard all rows with combinations of the GroupingVariables that are not present in the BootstrapData[[BaselineProcess]]:
    ### output <- output[uniqueCombinations, , on = names(uniqueCombinations)]
    
    
    if(RstoxData::hasUnit(BootstrapData[[BaselineProcess]][[TargetVariable]], property = "shortname")) {
        unit <- RstoxData::getUnit(BootstrapData[[BaselineProcess]][[TargetVariable]], property = "shortname")
        output <- cbind(output, Unit = unit)
    }
    
    return(output)
}

